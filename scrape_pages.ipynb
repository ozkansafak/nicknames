{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d70356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jf/qykqz6ks0vs56cb_zyf_7x_00000gn/T/ipykernel_3362/588965286.py:8: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import re, sys, random, glob, json, unidecode, unicodedata\n",
    "import ipdb, time, sys, os, pickle\n",
    "import requests \n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup  \n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Matplotlib Configuration\n",
    "pylab.rcParams.update({'legend.fontsize': 'medium',\n",
    "                       'font.size'      : 12,\n",
    "                       'figure.figsize' : (10, 10),\n",
    "                       'axes.labelsize' : 'medium',\n",
    "                       'axes.titlesize' : 'medium',\n",
    "                       'axes.grid'      : 'on',\n",
    "                       'xtick.labelsize': 'medium',\n",
    "                       'ytick.labelsize': 'medium'})\n",
    "\n",
    "def print_runtime(start: float, printer: bool = True) -> None:\n",
    "    end = time.time()\n",
    "    if printer:\n",
    "        print(f'Runtime: {int((end - start) // 60)} min {int((end - start) % 60):2d} sec')\n",
    "    else:\n",
    "        return f'({int((end - start) // 60)} min {int((end - start) % 60):2d} sec)'\n",
    "\n",
    "\n",
    "with open('urls.txt', 'r') as f:\n",
    "    urls = f.readlines()\n",
    "urls = [url[:-1] for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ca44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils functions\n",
    "from openai import OpenAI\n",
    "head_prompt = \"\"\"I'll give you an HTML element that's extracted from the web page of a company. I want you to estimate the likelihood \"\"\" +\\\n",
    "\"\"\"that the hyperlink in the HTML element is likely to lead to a page that's named something like \"About the Team\" or \"About Us\" or \"Our Team\" or \"\"\"+\\\n",
    "\"\"\"it leads to a Bio page of any of the employees in the company where I can get information about the employee's name, \"\"\" +\\\n",
    "\"\"\"phone number, email address etc. \\nProvide your estimate as a single integer number between 0 and 100, where 0 means very unlikely, \"\"\" +\\\n",
    "\"\"\"and 100 means absolutely certain. Do not include any other text or explanation in your response. \\n\"\"\" +\\\n",
    "\"\"\"Here's the HTML tag: \"\"\"\n",
    "client = OpenAI()\n",
    "\n",
    "def call_gpt(href, bios):\n",
    "    prompt = head_prompt + str(href)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers only and only in integer numeric values\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.01,\n",
    "        logprobs=False\n",
    "    ) \n",
    "    content = completion.choices[0].message.dict()['content']\n",
    "    estimate = int(float(content))\n",
    "    print(f'estimate:{str(estimate):4s} {href} ')\n",
    "    if estimate >= 40:\n",
    "        bios.append({\"URL\":href, \"estimate\":estimate})\n",
    "\n",
    "    return estimate\n",
    "\n",
    "\n",
    "def get_href(root_url, atag):\n",
    "    href = atag.get(\"href\")\n",
    "    if not urlparse(href).hostname:\n",
    "        href = urljoin(root_url, href)\n",
    "    if urlparse(href).hostname is not None and \\\n",
    "        not urlparse(href).hostname.endswith(urlparse(root_url).hostname) and not urlparse(root_url).hostname.endswith(urlparse(href).hostname):\n",
    "        print(f'        hostname mismatch: {urlparse(href).hostname} != {urlparse(root_url).hostname}')\n",
    "        return None\n",
    "    return href\n",
    "    \n",
    "    \n",
    "def get_atags(href):\n",
    "    try:\n",
    "        response = requests.get(href, timeout=8)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        atags = soup.find_all(\"a\") \n",
    "        if not response.ok:\n",
    "            print(f'    *** RESPONSE NOT OK!! *** status_code: {response.status_code} ')\n",
    "        return atags\n",
    "    except Exception:\n",
    "        print(f'    Exception at href: {href} {Exception}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9687980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 or 1365 main URL: http://mabusinessadvisors.com/\n",
      "    ==> new depth:0  len(queue):1\n",
      "    depth:0  estimate:0    http://mabusinessadvisors.com/ \n",
      "    *** RESPONSE NOT OK!! *** status_code: 403 \n",
      "    len(bios) 0 (0 min  0 sec)\n"
     ]
    }
   ],
   "source": [
    "## BFS\n",
    "\n",
    "from collections import deque\n",
    "start = time.time()\n",
    "bios = []\n",
    "seen = set()\n",
    "model = \"gpt-4\"\n",
    "\n",
    "for iu, root_url in enumerate(urls[139:140]):\n",
    "    print(f'\\n{iu} or {len(urls)} main URL: {root_url}')\n",
    "        \n",
    "    queue = deque([(BeautifulSoup(f'<a href=\"{root_url}\"/></a>', 'html.parser'), 0)]) \n",
    "    prev_depth = -1\n",
    "    while queue and queue[0][1] < 3: \n",
    "        atag, depth = queue.popleft() \n",
    "        if prev_depth != depth:\n",
    "            print(f'    ==> new depth:{depth}  len(queue):{len(queue)+1}')\n",
    "            prev_depth = depth\n",
    "        href = get_href(root_url, atag)\n",
    "        if href is None or href in seen:\n",
    "            continue\n",
    "        seen.add(href)\n",
    "        print(f'    depth:{depth} ', end=' ')\n",
    "\n",
    "        estimate = call_gpt(href, bios)\n",
    "        if depth > 1 and estimate == 0:\n",
    "            continue\n",
    "            \n",
    "        atags = get_atags(href)\n",
    "        if atags is None:\n",
    "            continue\n",
    "        for atag in atags:\n",
    "            href = atag.get(\"href\")\n",
    "            if not urlparse(href).hostname:\n",
    "                href = urljoin(root_url, href) \n",
    "            if urlparse(href).hostname is not None and \\\n",
    "                not urlparse(href).hostname.endswith(urlparse(root_url).hostname) and not urlparse(root_url).hostname.endswith(urlparse(href).hostname):\n",
    "                continue\n",
    "            queue.append((atag,depth+1))\n",
    "        \n",
    "    print(f'    len(bios) {len(bios)} {print_runtime(start, False)}')\n",
    "\n",
    "# with open ('bios.pkl', 'wb') as f:\n",
    "#     pickle.dump(bios, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c53f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://mabusinessadvisors.com/', 'http://mabusinessadvisors.com/')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_url, href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "961aaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   8792 chars  http://goldstarbbaz.com/OurTeam.aspx \n",
      "    1     52 chars  https://gottesman-company.com/about/ \n",
      "    2     52 chars  https://gottesman-company.com/team/ \n",
      "    3   1821 chars  https://www.greenbridgebrokers.com/copy-of-about \n",
      "    4   6986 chars  https://www.greenbridgebrokers.com/about \n",
      "    5   9855 chars  https://hardingbusinessfl.com/about/ \n",
      "    6   9855 chars  https://hardingbusinessfl.com/about/#who-about \n",
      "    7   9855 chars  https://hardingbusinessfl.com/about/#testimonials-about \n",
      "    8   5207 chars  https://www.harvestbusiness.com/about-1 \n",
      "    9   3241 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/ \n",
      "   10   5385 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-bill-arman/ \n",
      "   11   5210 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-ed-laflamme/ \n",
      "   12   3145 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-cindy-code/ \n",
      "   13   5046 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-steve-cesare/ \n",
      "   14   3999 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-alison-hoffman/ \n",
      "   15   5244 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-chris-darnell/ \n",
      "   16   7796 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/harvester-jud-griggs/ \n",
      "   17   4528 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/book-a-harvester/ \n",
      "   18   8882 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/book-a-harvester/harvester-eds-speaking-topics/ \n",
      "   19   6508 chars  https://harvestlandscapeconsulting.com/consulting/meet-the-harvesters/book-a-harvester/harvester-steves-speaking-topic/ \n",
      "   20   2778 chars  https://harvestlandscapeconsulting.com/consulting/harvest-group-partners/ \n",
      "   21   5210 chars  https://harvestlandscapeconsulting.com/about/ed-laflamme/ \n",
      "   22   5385 chars  https://harvestlandscapeconsulting.com/about/bill-arman/ \n",
      "   23   5046 chars  https://harvestlandscapeconsulting.com/about/steve-cesare/ \n",
      "   24   2635 chars  https://harvestlandscapeconsulting.com/course-category/people/ \n",
      "   25   6965 chars  https://harvestlandscapeconsulting.com/author/harvester-ed/ \n",
      "   26   6964 chars  https://harvestlandscapeconsulting.com/author/harvester-steve/ \n",
      "   27   6965 chars  https://harvestlandscapeconsulting.com/author/harvester-alison/ \n",
      "   28  11028 chars  https://harvestlandscapeconsulting.com/the-team-that-brought-you-to-this-point/ \n",
      "   29   3815 chars  https://harvestlandscapeconsulting.com/roger-braswell-harvest-group-sit-down/ \n",
      "   30   6150 chars  https://harvestlandscapeconsulting.com/isaac-roberts-harvest-group-sit-down/ \n",
      "   31   6968 chars  https://harvestlandscapeconsulting.com/author/harvester-cindy/ \n",
      "   32   3921 chars  https://harvestlandscapeconsulting.com/david-snodgrass-harvest-group-sit-down/ \n",
      "   33   6404 chars  https://harvestlandscapeconsulting.com/charlie-hall-harvest-group-sit-down/ \n",
      "   34   6417 chars  https://harvestlandscapeconsulting.com/kurt-kluznik-harvest-group-sit-down/ \n",
      "   35   5046 chars  https://harvestlandscapeconsulting.com/wp/connect/contact/steve/ \n",
      "   36   3191 chars  http://ibrgroupcorp.com/about/ \n",
      "   37   1011 chars  http://ibrgroupcorp.com/author/summy/ \n",
      "   38   4114 chars  http://iconicresourcesllc.com/About.html \n",
      "   39  13639 chars  https://innovativeba.com/about/ \n",
      "   40  15361 chars  https://innovativeba.com/terry-lammers/ \n",
      "   41  13641 chars  http://innovativeba.com/about/ \n",
      "   42   2509 chars  https://innovativeba.com/author/terry-lammers/ \n",
      "   43   4060 chars  https://www.kcapex.com/about-us/ \n",
      "   44   3183 chars  https://www.kcapex.com/kansas-city-team/ \n",
      "   45   4856 chars  https://www.kcapex.com/author/apexadmin/ \n",
      "   46   3000 chars  https://www.kcapex.com/episode-100-the-apex-team/ \n",
      "   47   3183 chars  http://www.kcapex.com/kansas-city-team/ \n",
      "   48   4339 chars  https://www.kcapex.com/know-your-broker-jeff-crooks/ \n",
      "   49   5807 chars  https://www.kcapex.com/know-your-broker-debbie-small/ \n",
      "   50   4303 chars  https://www.kcapex.com/know-broker-jay-kvasnicka/ \n",
      "   51   6590 chars  https://www.kcapex.com/know-your-broker-chuck-campbell/ \n",
      "   52   4450 chars  https://www.kcapex.com/know-broker-ron-kleier/ \n",
      "   53   4372 chars  https://www.kcapex.com/know-broker-valerie-vaughn/ \n",
      "   54   6143 chars  https://www.kcapex.com/know-your-broker-ryan-wenrich/ \n",
      "   55   6173 chars  https://www.kcapex.com/know-your-broker-andy-cavanaugh/ \n",
      "   56   4926 chars  https://www.kcapex.com/know-your-broker-wayne-swisher/ \n",
      "   57   4230 chars  https://www.kcapex.com/know-broker-jerry-meinert/ \n",
      "   58   5716 chars  https://www.kcapex.com/know-your-broker-doug-hubler/ \n",
      "   59   3000 chars  https://www.kcapex.com/episode-100-the-apex-team/#respond \n",
      "   60   3000 chars  http://kcapex.com/episode-100-the-apex-team/#respond \n",
      "   61   4026 chars  https://kellybusinessadvisors.com/about/our-team/advisor-kelly/ \n",
      "   62   2055 chars  https://kellybusinessadvisors.com/about/our-team/george-metos/ \n",
      "   63   2325 chars  https://kellybusinessadvisors.com/about/our-team/kiely-kelly/ \n",
      "   64   1459 chars  http://kellybusinessadvisors.com/advisor-kelly/ \n",
      "   65   5375 chars  https://kmfbusinessadvisors.com/about/ \n",
      "   66  url: http://leftcoastcapital.com/about-left-coast-capital-resources  I had an exception HTTPConnectionPool(host='leftcoastcapital.com', port=80): Max retries exceeded with url: /about-left-coast-capital-resources (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x2a7658430>, 'Connection to leftcoastcapital.com timed out. (connect timeout=8)'))\n",
      "   67  url: http://leftcoastcapital.com/about-left-coast-capital-resources/left-coast-capital-resources  I had an exception HTTPConnectionPool(host='leftcoastcapital.com', port=80): Max retries exceeded with url: /about-left-coast-capital-resources/left-coast-capital-resources (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x2a7658d60>, 'Connection to leftcoastcapital.com timed out. (connect timeout=8)'))\n",
      "   68  url: http://leftcoastcapital.com/about-left-coast-capital-resources/eric-seifert  I had an exception HTTPConnectionPool(host='leftcoastcapital.com', port=80): Max retries exceeded with url: /about-left-coast-capital-resources/eric-seifert (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x2a7663640>, 'Connection to leftcoastcapital.com timed out. (connect timeout=8)'))\n",
      "   69  url: http://leftcoastcapital.com/about-left-coast-capital-resources/our-team  I had an exception HTTPConnectionPool(host='leftcoastcapital.com', port=80): Max retries exceeded with url: /about-left-coast-capital-resources/our-team (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x2a7663f40>, 'Connection to leftcoastcapital.com timed out. (connect timeout=8)'))\n",
      "   70   7323 chars  https://livmo.com/about-us/ \n",
      "   71     38 chars  http://mabusinessadvisors.com/johnmittelstet \n",
      "   72   5056 chars  https://magnusbusinessgroup.com/about/ \n",
      "   73  10059 chars  https://www.midstreet.com/about-us \n",
      "   74   5429 chars  http://midstreet.com/#jeffery-baxter--cbi--mami \n",
      "   75   5429 chars  http://midstreet.com/#erik-sullivan \n",
      "   76   5429 chars  http://midstreet.com/#jonah-pollone--cbi \n",
      "   77   5429 chars  http://midstreet.com/#jeff-baxter-jr \n",
      "   78   5429 chars  http://midstreet.com/#joshua-moore \n"
     ]
    }
   ],
   "source": [
    "# extract the text out of candidates \"bios\"\n",
    "def extract_text_from_url(url, data, visited_urls):\n",
    "    if url in visited_urls:\n",
    "        print(f'url already in visited_urls: {url}')\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=8)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = soup.text\n",
    "    except Exception as e:\n",
    "        stdout = f'{idx:5d}  url: {url}  I had an exception {e}'\n",
    "        print(stdout)\n",
    "        visited_urls.add(url)\n",
    "        data[url] = stdout\n",
    "        return None, None\n",
    "    \n",
    "    data[url] = text\n",
    "    visited_urls.add(url)\n",
    "    print(f'{idx:5d} {len(data[url]):6d} chars  {url} ')\n",
    "    return text\n",
    "\n",
    "data = dict()\n",
    "visited_urls = set()\n",
    "prev_num_chars = -1\n",
    "for idx, bio in enumerate(bios):\n",
    "    url = bio['URL']\n",
    "    text = extract_text_from_url(url, data, visited_urls)\n",
    "    num_chars = len(text)\n",
    "    if prev_num_chars == num_chars:\n",
    "        del data[url]\n",
    "    prev_num_chars = num_chars\n",
    "    time.sleep(.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dfd575e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> replacing \",\n",
      "\" with \",\" (0 min  3 sec)\n",
      "idx:2 finished. len(results):1 (0 min  3 sec) \n",
      "\n",
      "Runtime: 0 min  3 sec\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "results = []\n",
    "start = time.time()\n",
    "model = \"gpt-4\"\n",
    "\n",
    "\n",
    "for idx, (url,  text) in enumerate(data.items()):\n",
    "    s0 = time.time()\n",
    "    text = data[url]\n",
    "\n",
    "    prompt = \"\"\"Here's some text I extracted from a webpage:\\n\"\"\" + text +\\\n",
    "    \"\"\" \\n Extract the following Named Entities from the above text: \"First Name\", \"Middle Name\", \"Last Name\", \"Profession\", \"\"\" +\\\n",
    "    \"\"\"Company Name\", \"Phone Number\", \"Email\", \"Address\" , \"State\", \"Zipcode\", \"Bio\", \"Specialty Areas\" \"\"\" +\\\n",
    "    \"\"\"and  put them in a json file with the keys I specified. If the information is missing \"\"\" +\\\n",
    "    \"\"\"leave the value of that key blank. \"\"\"+\\\n",
    "    \"\"\"Only return a JSON formatted text. Don't say anything else, don't write any python code. \"\"\" +\\\n",
    "    \"\"\"If the given text contains more than one individual, create a separate json file and return a list of json files\"\"\"\n",
    "    \"\"\"If any of the values in the JSON file is a list of items, make sure you wrap the items in square brackets compatible with python syntax.\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that extracts named entities from provided text, and returns an answer that's only comprised of \" +\\\n",
    "         \"json formatted text\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    content = completion.choices[0].message.dict()['content']\n",
    "    if \",}\" in content:\n",
    "        print('==> replacing \",}\", \"}\" ' + f\" {print_runtime(start, False)}\")\n",
    "        content = content.replace(',}', '}')\n",
    "    if \",\\n\" in content:\n",
    "        print(f'==> replacing \",\\n\" with \",\"' + f\" {print_runtime(start, False)}\")\n",
    "        content = content.replace(\",\\n\", \",\")\n",
    "\n",
    "    json_output = json.loads(content)\n",
    "    if type(json_output) == list:\n",
    "        for item in json_output:\n",
    "            item['URL'] = url\n",
    "            results.append(item)\n",
    "    else:\n",
    "        json_output['URL'] = url\n",
    "        results.append(json_output)\n",
    "    print(f'idx:{idx} finished. len(results):{len(results)} {print_runtime(s0, False)} \\n')\n",
    "\n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc0050bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Middle Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Email</th>\n",
       "      <th>Address</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Bio</th>\n",
       "      <th>Specialty Areas</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Green Bridge Advisor</td>\n",
       "      <td>970.286.0052</td>\n",
       "      <td>christian@greenbridgebrokers.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Retail, Service, Agricultural, Professional, H...</td>\n",
       "      <td>https://www.greenbridgebrokers.com/copy-of-about</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Middle Name Last Name  Profession          Company Name  \\\n",
       "0                                   Consulting  Green Bridge Advisor   \n",
       "\n",
       "   Phone Number                             Email Address State Zipcode Bio  \\\n",
       "0  970.286.0052  christian@greenbridgebrokers.com                             \n",
       "\n",
       "                                     Specialty Areas  \\\n",
       "0  Retail, Service, Agricultural, Professional, H...   \n",
       "\n",
       "                                                URL  \n",
       "0  https://www.greenbridgebrokers.com/copy-of-about  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('named_entities.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cd9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb4af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e0162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28acf5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3ae28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
